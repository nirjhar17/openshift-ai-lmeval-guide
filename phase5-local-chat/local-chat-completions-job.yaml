apiVersion: trustyai.opendatahub.io/v1alpha1
kind: LMEvalJob
metadata:
  name: local-chat-eval
  namespace: lmeval-testing
spec:
  allowOnline: true
  allowCodeExecution: true

  # Model - Chat Completions
  model: local-chat-completions
  
  modelArgs:
    - name: model
      value: "Qwen/Qwen3-0.6B"
    - name: base_url
      value: "http://openshift-ai-inference-openshift-ai-inference.openshift-ingress.svc.cluster.local:80/my-first-model/qwen3-0-6b/v1/chat/completions"
    # Use a tokenizer we know works from Phase 3
    - name: tokenizer
      value: google/flan-t5-small
    - name: num_concurrent
      value: "1"
    - name: max_retries
      value: "3"

  # Enable chat template via CLI flag
  chatTemplate:
    enabled: true

  # Task - Same generation-based task
  taskList:
    taskRecipes:
      - card:
          name: "cards.wnli"
        template:
          name: "templates.classification.multi_class.relation.default"

  limit: "10"
  batchSize: "1"
  logSamples: true
